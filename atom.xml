<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Fseast Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-09-10T17:13:40.190Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>fseast</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>虚拟机上的Hadoop伪分布式和完全分布式的搭建</title>
    <link href="http://yoursite.com/2018/02/23/buy-%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%8A%E7%9A%84Hadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%92%8C%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2018/02/23/buy-虚拟机上的Hadoop伪分布式和完全分布式的搭建/</id>
    <published>2018-02-23T01:10:11.000Z</published>
    <updated>2019-09-10T17:13:40.190Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Hadoop"><a href="#一、Hadoop" class="headerlink" title="一、Hadoop"></a>一、Hadoop</h2><h3 id="1-Hadoop的组成"><a href="#1-Hadoop的组成" class="headerlink" title="1.Hadoop的组成"></a>1.Hadoop的组成</h3><p>简单了解一下Hadoop2.x时代的组成：<br>HDFS  负责数据存储<br>Yarn  负责资源调度<br>MapReduce  负责计算<br>Common    辅助工具</p><h4 id="1-1HDFS架构概述"><a href="#1-1HDFS架构概述" class="headerlink" title="1.1HDFS架构概述"></a>1.1HDFS架构概述</h4><p>HDFS(Hadoop Distributed File System)<br>（1）NameNode (nn)：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的快列表和块所在的DataNode等。<br>（2）DataNode (dn)：在本地文件系统存储文件块数据，以及块数据的校验和。<br>（3）Secondary NameNode (2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p><h4 id="1-2YARN架构概述"><a href="#1-2YARN架构概述" class="headerlink" title="1.2YARN架构概述"></a>1.2YARN架构概述</h4><ol><li>ResourceManager（RM）主要作用如下：<br>（1）处理客户端请求<br>（2）监控NodeManager<br>（3）启动或监控ApplicationMaster<br>（4）资源的分配与调度</li><li>NodeManger（NM）主要作用如下：<br>（1）管理单个节点上的资源<br>（2）处理来自ResourceManager的命令<br>（3）处理来自ApplicationMaster的命令</li><li>ApplicationMaster（AM）作用如下：<br>（1）负责数据的切分<br>（2）为应用程序申请资源并分配给内部的任务。<br>（3）任务的监控与容错。</li><li>Container<br>Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。<br><img src="https://img-blog.csdnimg.cn/20190822152546302.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li></ol><h4 id="1-3MapReduce架构概述"><a href="#1-3MapReduce架构概述" class="headerlink" title="1.3MapReduce架构概述"></a>1.3MapReduce架构概述</h4><p>MapReduce 将计算过程分为两个阶段：Map和Reduce：<br>（1）Map阶段并行处理输入数据。<br>（2）Reduce阶段对Map结果进行汇总</p><h2 id="二、Hadoop的搭建"><a href="#二、Hadoop的搭建" class="headerlink" title="二、Hadoop的搭建"></a>二、Hadoop的搭建</h2><h3 id="1-运行环境"><a href="#1-运行环境" class="headerlink" title="1.运行环境"></a>1.运行环境</h3><p>前期准备这一部分看需求进行配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">修改 vim /etc/udev/rules.d/70-persistent-net.rules , 拷贝mac地址</span><br><span class="line">修改 vim /etc/sysconfig/network-scripts/ifcfg-eth0 , 修改mac地址以及IP地址</span><br><span class="line">修改 vim /etc/sysconfig/network  修改主机名</span><br><span class="line">修改 vim /etc/hosts ,配置 IP与主机名的映射.</span><br></pre></td></tr></table></figure></p><ol><li>修改主机名</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network</span><br></pre></td></tr></table></figure><p>配置IP与主机名的映射：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br></pre></td></tr></table></figure><p>添加如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">192.168.17.101 hadoop101</span><br><span class="line">192.168.17.102 hadoop102</span><br><span class="line">192.168.17.103 hadoop103</span><br><span class="line">192.168.17.104 hadoop104</span><br></pre></td></tr></table></figure></p><ol><li>关闭防火墙<br>查看防火墙状态：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service iptables status</span><br></pre></td></tr></table></figure></li></ol><p>临时关闭防火墙：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop</span><br></pre></td></tr></table></figure><p>开机时关闭防火墙：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure><ol><li><p>创建Linux用户<br>这里添加了名为 fseast 的新用户：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useradd fseast</span><br><span class="line">passwd fseast</span><br></pre></td></tr></table></figure></li><li><p>配置Linux用户具有root权限<br>对/etc/sudoers文件添加：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fseast ALL=(ALL)       NOPASSWD:ALL</span><br></pre></td></tr></table></figure><p>接下来的操作都将使用fseast用户操作</p><ol><li>创建文件夹<br>在/opt下创建 software 和 module 两个目录，一个存放软件包，一个放解压后的文件。（使用fseast用户创建要使用sudo）<br>改变这两个目录所有者：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown fseast:fseast 目录</span><br></pre></td></tr></table></figure></li></ol><p>关闭图形化界面：<br>修改 /etc/inittab<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id:3:initdefault:</span><br></pre></td></tr></table></figure></p><h4 id="1-1安装JDK"><a href="#1-1安装JDK" class="headerlink" title="1.1安装JDK"></a>1.1安装JDK</h4><p>这里使用的Linux版本是Centos6.8，<br>JDK版本是1.8，<br>Hadoop版本是2.7.2</p><ol><li>安装JDK<br>先把软件包上传到software 目录<br>解压：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li></ol><p>配置环境变量：<br>在/etc/profile文件加上：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure></p><p>使其生效：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>测试jdk是否安装成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure></p><h4 id="1-2安装Hadoop"><a href="#1-2安装Hadoop" class="headerlink" title="1.2安装Hadoop"></a>1.2安装Hadoop</h4><p>Hadoop下载地址：<br><a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/" target="_blank" rel="noopener">https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/</a></p><ol><li>上传安装包到software，解压：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li></ol><p>解压后查看目录结构：<br><img src="https://img-blog.csdnimg.cn/20190716190919341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（1）bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本<br>（2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件<br>（3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）<br>（4）sbin目录：存放启动或停止Hadoop相关服务的脚本<br>（5）share目录：存放Hadoop的依赖jar包、文档、和官方案例</p><ol><li>将Hadoop添加到环境变量：<br>在/etc/profile文件添加：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure></li></ol><p>使其生效：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>测试是否安装成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure></p><h3 id="2-伪分布式运行模式"><a href="#2-伪分布式运行模式" class="headerlink" title="2.伪分布式运行模式"></a>2.伪分布式运行模式</h3><h4 id="2-1配置文件说明"><a href="#2-1配置文件说明" class="headerlink" title="2.1配置文件说明"></a>2.1配置文件说明</h4><p>Hadoop配置文件分为两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。<br>（1）默认配置文件：<br><img src="https://img-blog.csdnimg.cn/20190720204355548.png" alt="在这里插入图片描述"><br>（2）自定义配置文件:<br>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p><h4 id="2-2启动HDFS并运行MapReduce程序"><a href="#2-2启动HDFS并运行MapReduce程序" class="headerlink" title="2.2启动HDFS并运行MapReduce程序"></a>2.2启动HDFS并运行MapReduce程序</h4><p>(1). 修改配置文件：<br>进入<code>/opt/module/hadoop-2.7.2/etc/hadoop</code> 目录</p><font color="DeepSkyBlue" size="3">（a）配置：hadoop-env.sh</font><br>修改改配置文件的JAVA_HOME路径（其实单台节点不配JAVA_HOME也可以读的到该变量）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><br><br><font color="DeepSkyBlue" size="3">（b）配置：core-site.xml</font><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop101:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><br><br><font color="DeepSkyBlue" size="3">（c）配置：hdfs-site.xml</font><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><br><br>(2). 启动集群<br>（a）格式化NameNode（第一次启动时格式化，以后就不要总格式化，原因下面说）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure><br><br>（b）启动NameNode<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure><br><br>（c）启动DataNode<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure><br><br>(3). 查看集群<br>（a）查看是否启动成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop101 hadoop-2.7.2]$ jps</span><br><span class="line">5203 DataNode</span><br><span class="line">5353 Jps</span><br><span class="line">5102 NameNode</span><br></pre></td></tr></table></figure><br><br>（b）web端查看HDFS文件系统<br><a href="http://hadoop101:50070/" target="_blank" rel="noopener">http://hadoop101:50070/</a><br>使用hadoop101的话需要配置Windows的hosts文件。<br>成功进入：<br><img src="https://img-blog.csdnimg.cn/20190716204830465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">（c）查看产生的Log日志<br>要习惯根据日志提示信息去分析问题、解决Bug。<br>这里日志文件目录为：/opt/module/hadoop-2.7.2/logs<br><br>(4).  操作集群：<br>（a）在HDFS文件系统上创建一个input文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir -p /user/fseast/input</span><br></pre></td></tr></table></figure><br><br>（b）将测试文件内容上传到文件系统上<br>先在本地创建一个文件wc.input，并写入一些单词，然后上传到文件系统上：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put wc.input /user/fseast/input</span><br></pre></td></tr></table></figure><br><br>（c）运行MapReduce程序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input/ /user/fseast/output</span><br></pre></td></tr></table></figure><br><br>这个 /user/fseast/output目录不用提前在HDFS创建。<br><br>（d）查看输出结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cat /user/fseast/output/*</span><br></pre></td></tr></table></figure><br><br>浏览器查看：<br><img src="https://img-blog.csdnimg.cn/20190716212843546.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><br><strong>【为什么不能重复格式化NameNode？】</strong><br>Hadoop的NameNode和DataNode有对应的clusterID，NameNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current/VERSION文件中，DataNode的cID在/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/VERSION文件中，正常情况下这NameNode和DataNode的cID要一致。当重复格式化NameNode的时候，会导致NameNode的clusterID与DataNode的clusterID不一致。启动的时候便会出现问题。<br>所以，以后一定要格式化的时候，先关闭进程，删除/opt/module/hadoop-2.7.2下的data和logs这两个目录。<br>我截了NameNode的clusterID与DataNode的clusterID：<br><img src="https://img-blog.csdnimg.cn/20190716203810635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20190716204001540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>#### 2.3启动YARN并运行MapReduce程序<br>（1）配置集群<br><font color="DeepSkyBlue" size="3">（a）配置yarn-env.sh</font><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><br><br><font color="DeepSkyBlue" size="3">（b）配置yarn-site.xml</font><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><br><br><font color="DeepSkyBlue" size="3">（c）配置：mapred-env.sh</font><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><br><br><font color="DeepSkyBlue" size="3">（d）配置： (对mapred-site.xml.template复制一份并重新命名为) mapred-site.xml</font><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在YARN上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>切记上面的配置都要在 <code>&lt;configuration&gt;&lt;/configuration&gt;</code>  内</p><p>（2）启动集群<br>（a）启动前必须保证NameNode和DataNode已经启动<br>（b）启动ResourceManager<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure></p><p>（c）启动NodeManager<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure></p><p>截图：<br><img src="https://img-blog.csdnimg.cn/20190717163826446.png" alt="在这里插入图片描述"><br>（3）集群操作<br>（a）YARN的浏览器页面查看：<a href="http://hadoop101:8088" target="_blank" rel="noopener">http://hadoop101:8088</a><br>如图所示：<br><img src="https://img-blog.csdnimg.cn/20190717164054991.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">（b）删除文件系统上的output文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rm -R /user/fseast/output</span><br></pre></td></tr></table></figure></p><p>（c）执行MapReduce程序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output</span><br></pre></td></tr></table></figure></p><p>执行MapReduce程序的时候，如果你一直刷新页面，就可以看的到变化：<br><img src="https://img-blog.csdnimg.cn/20190717165519297.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20190717165554655.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="2-4配置历史服务器"><a href="#2-4配置历史服务器" class="headerlink" title="2.4配置历史服务器"></a>2.4配置历史服务器</h4><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p><ol><li><p><font color="DeepSkyBlue" size="3">配置mapred-site.xml:</font></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>启动历史服务器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure></li><li><p>查看历史服务器是否启动：<br><img src="https://img-blog.csdnimg.cn/20190717181121553.png" alt="hadoop历史服务器"></p></li><li><p>查看JobHistory：<a href="http://hadoop101:19888/jobhistory" target="_blank" rel="noopener">http://hadoop101:19888/jobhistory</a><br>如图所示：<br><img src="https://img-blog.csdnimg.cn/20190717181700122.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">点击上方圈起来的位置：<br><img src="https://img-blog.csdnimg.cn/20190717181837376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">再点击圈起来的地方：<br><img src="https://img-blog.csdnimg.cn/20190717181913114.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">他说没有开启聚集，那就开启一下日志的聚集：</p></li></ol><h4 id="2-5配置日志的聚集"><a href="#2-5配置日志的聚集" class="headerlink" title="2.5配置日志的聚集"></a>2.5配置日志的聚集</h4><ol><li><font color="DeepSkyBlue" size="3">配置yarn-site.xml:</font></li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ol><li><p>关闭NodeManager 、ResourceManager和HistoryServer</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop101 hadoop]$ yarn-daemon.sh stop resourcemanager</span><br><span class="line">[fseast@hadoop101 hadoop]$ yarn-daemon.sh stop nodemanager</span><br><span class="line">[fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh stop historyserver</span><br></pre></td></tr></table></figure></li><li><p>启动NodeManager 、ResourceManager和HistoryServer</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop101 hadoop]$ yarn-daemon.sh start resourcemanager</span><br><span class="line">[fseast@hadoop101 hadoop]$ yarn-daemon.sh start nodemanager</span><br><span class="line">[fseast@hadoop101 hadoop]$ mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure></li><li><p>删除HDFS上已经存在的输出文件</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rm -R /user/fseast/output</span><br></pre></td></tr></table></figure><ol><li>执行WordCount程序</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/fseast/input /user/fseast/output</span><br></pre></td></tr></table></figure><p>再按照上面，查看日志，<br>先进JobHistory，<a href="http://hadoop101:19888/jobhistory" target="_blank" rel="noopener">http://hadoop101:19888/jobhistory</a><br><img src="https://img-blog.csdnimg.cn/20190717183938407.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20190717184001971.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20190717184115874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20190717184200523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="3-完全分布式运行模式"><a href="#3-完全分布式运行模式" class="headerlink" title="3.完全分布式运行模式"></a>3.完全分布式运行模式</h3><h4 id="3-1虚拟机准备"><a href="#3-1虚拟机准备" class="headerlink" title="3.1虚拟机准备"></a>3.1虚拟机准备</h4><p>再准备三台虚拟机：hadoop102、hadoop103、hadoop104，修改主机名，IP地址，配置/etc/hosts文件，</p><h4 id="3-2编写集群分发脚本"><a href="#3-2编写集群分发脚本" class="headerlink" title="3.2编写集群分发脚本"></a>3.2编写集群分发脚本</h4><ol><li>scp（secure copy）安全拷贝<br>把上面安装好的jdk和Hadoop发送到新建的三台虚拟机(记得先停掉hadoop的那些进程)：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop102:/opt/</span><br><span class="line">[fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop103:/opt/</span><br><span class="line">[fseast@hadoop101 opt]$ scp -r /opt/module root@hadoop104:/opt/</span><br></pre></td></tr></table></figure><p>改变传过去目录的所有者：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 opt]$ sudo chown fseast:fseast -R module/</span><br></pre></td></tr></table></figure></p><ol><li>rsync 远程同步工具<br>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。<br>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</li></ol><p>实例：<br>把hadoop101机器上的/opt/software目录同步到hadoop102服务器的root用户下的/opt/目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop101 opt]$ sudo rsync -av /opt/software/ hadoop102:/opt/software</span><br></pre></td></tr></table></figure></p><p>拷贝环境变量配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop101 etc]$ sudo rsync -av /etc/profile hadoop102:/etc/profile</span><br></pre></td></tr></table></figure><p>使环境变量生效：<code>source /etc/profile</code></p><p><strong>脚本实现：</strong><br>目的：后面在hadoop102节点上修改了某些文件时，不需要一个个传到另外两个节点，启动 shell 脚本时加上参数即可：<br>（a）在/home/fseast目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 ~]$ mkdir bin</span><br><span class="line">[fseast@hadoop102 ~]$ cd bin/</span><br><span class="line">[fseast@hadoop102 bin]$ touch xsync</span><br><span class="line">[fseast@hadoop102 bin]$ vim xsync</span><br></pre></td></tr></table></figure><p>在该文件中编写如下代码：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>1 获取输入参数个数，如果没有参数，直接退出</span><br><span class="line">pcount=$#</span><br><span class="line">if ((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>2 获取文件名称</span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line">echo fname=$fname</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>3 获取上级目录到绝对路径</span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo pdir=$pdir</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>4 获取当前用户名称</span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>5 循环</span><br><span class="line">for((host=103; host&lt;105; host++)); do</span><br><span class="line">        echo ------------------- hadoop$host --------------</span><br><span class="line">        rsync -av $pdir/$fname $user@hadoop$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p><p>（b）修改脚本 xsync 具有执行权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 bin]$ chmod 777 xsync</span><br></pre></td></tr></table></figure><p>（c）调用脚本形式：xsync 文件名称<br>如：<br>把/home/fseast/bin同步到其他两台节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 bin]$ xsync /home/fseast/bin</span><br></pre></td></tr></table></figure><p>注意：如果将xsync放到/home/fseast/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。出现不能使用的情况，大多是全局变量PATH没有/home/fseast/bin路径。</p><h4 id="3-3集群配置"><a href="#3-3集群配置" class="headerlink" title="3.3集群配置"></a>3.3集群配置</h4><p><font color="Red" size="3">以下的完全分布式配置是完整的配置，也就是默认没有配置伪分布式情况下的。</font></p><p><table><tr align="left"><td bgcolor="#F0FFF0">配置文件三个.env结尾的文件都只是配了 JAVA_HOME ，所以也可不配，只需要在/home/fseast/.bashrc文件中加上 source /etc/profile</td></tr></table><br>NameNode，ResourceManager，SecondaryNameNode三个节点比较耗资源，最好不要放在同一台机器。</p><ol><li>集群部署规划<br><img src="https://img-blog.csdnimg.cn/20190717203826723.png" alt="在这里插入图片描述"></li><li>SSH免密登录配置<br>(1) 生成公钥和私钥：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 ~]$ ssh-keygen -t rsa</span><br></pre></td></tr></table></figure></li></ol><p>然后按三次回车，就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p><p>(2) 将公钥拷贝到要免密登录的目标机器上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[fseast@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[fseast@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure></p><p>在hadoop103也要做相同操作，这里hadoop104可以操作也可以不做。</p><ol><li>配置集群<br>配置集群的文件在hadoop102节点配置，配置完后再使用上面的脚本同步就好。<br>这里是按照没有配伪分布式情况下的配置文件，在前面配过伪分布式那么有些配过了那就不需要重复配了。<br>所用需要配置的文件都在目录：<br>/opt/module/hadoop-2.7.2/etc/hadoop/slaves</li></ol><p>（1）核心配置文件</p><p><font color="DeepSkyBlue" size="3">配置core-site.xml</font>（伪分布式配过，只需要修改NameNode的节点名即可。）：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>（2）HDFS配置文件</p><p><font color="DeepSkyBlue" size="3">配置hadoop-env.sh</font>（伪分布式配过）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><p><font color="DeepSkyBlue" size="3">配置hdfs-site.xml</font>（副本数量伪分布式配过，不过需要修改）：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>（3）YARN配置文件</p><p><font color="DeepSkyBlue" size="3">配置yarn-env.sh</font>（伪分布式配过）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><p><font color="DeepSkyBlue" size="3">配置yarn-site.xml</font>（伪分布式配过，需要修改ResourceManager的地址，前面配的日志聚集也可保留）：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>（4）MapReduce配置文件</p><p><font color="DeepSkyBlue" size="3">配置mapred-env.sh</font>（伪分布式配过）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><p><font color="DeepSkyBlue" size="3">配置mapred-site.xml</font>（伪分布配过，没配过的需要复制mapred-site.xml.template文件并改名为mapred-site.xml再配置）：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>（5）<font color="DeepSkyBlue" size="3">配置slaves</font>（没有配过）：<br>为了群起集群的时候，知道哪台节点是从节点<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure></p><ol><li>在集群上分发配置好的Hadoop配置文件</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop]$ xsync /opt/module/hadoop-2.7.2/</span><br></pre></td></tr></table></figure><ol><li>群起集群<br>（1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure></li></ol><p>（2）启动HDFS<br>在hadoop102（NameNode）执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure></p><p>（3）启动YARN<br>在hadoop103（ResourceManager）执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure><p>（4）Web端查看SecondaryNameNode：<br><a href="http://hadoop104:50090" target="_blank" rel="noopener">http://hadoop104:50090</a></p><p><img src="https://img-blog.csdnimg.cn/20190717225014645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h5 id="集群启动-停止方式总结"><a href="#集群启动-停止方式总结" class="headerlink" title="集群启动/停止方式总结"></a>集群启动/停止方式总结</h5><ol><li><p>各个服务组件逐一启动/停止<br> （1）分别启动/停止HDFS组件</p><pre><code>hadoop-daemon.sh  start / stop   namenode / datanode / secondarynamenodehadoop-daemon.sh  start / stop   datanode hadoop-daemon.sh  start / stop   secondarynamenode</code></pre><p> （2）启动/停止YARN</p><pre><code>yarn-daemon.sh  start / stop  resourcemanageryarn-daemon.sh  start / stop  nodemanager</code></pre></li><li><p>各个模块分开启动/停止（配置ssh是前提）<br> （1）整体启动/停止HDFS</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh   /  stop-dfs.sh</span><br></pre></td></tr></table></figure><p>（2）整体启动/停止YARN<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh  /  stop-yarn.sh</span><br></pre></td></tr></table></figure></p><p><a href="https://blog.csdn.net/fseast/article/details/96432838" target="_blank" rel="noopener">下一篇：阿里云服务器上的Hadoop伪分布式和完全分布式的搭建</a><a href="http://hfbin.cn/2018/02/21/buy-%E5%85%B3%E4%BA%8E%E6%95%99%E7%A8%8B%E3%80%81%E8%8E%B7%E5%8F%96%E6%96%B9%E5%BC%8F%E3%80%81%E6%B8%A9%E9%A6%A8%E6%8F%90%E7%A4%BA/" target="_blank" rel="noopener">http://hfbin.cn/2018/02/21/buy-%E5%85%B3%E4%BA%8E%E6%95%99%E7%A8%8B%E3%80%81%E8%8E%B7%E5%8F%96%E6%96%B9%E5%BC%8F%E3%80%81%E6%B8%A9%E9%A6%A8%E6%8F%90%E7%A4%BA/</a>)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、Hadoop&quot;&gt;&lt;a href=&quot;#一、Hadoop&quot; class=&quot;headerlink&quot; title=&quot;一、Hadoop&quot;&gt;&lt;/a&gt;一、Hadoop&lt;/h2&gt;&lt;h3 id=&quot;1-Hadoop的组成&quot;&gt;&lt;a href=&quot;#1-Hadoop的组成&quot; class
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>BAT大牛亲授 基于ElasticSearch的搜房网实战</title>
    <link href="http://yoursite.com/2018/02/22/buy-BAT%E5%A4%A7%E7%89%9B%E4%BA%B2%E6%8E%88%20%E5%9F%BA%E4%BA%8EElasticSearch%E7%9A%84%E6%90%9C%E6%88%BF%E7%BD%91%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2018/02/22/buy-BAT大牛亲授 基于ElasticSearch的搜房网实战/</id>
    <published>2018-02-22T08:49:11.000Z</published>
    <updated>2018-02-22T08:05:12.117Z</updated>
    
    <content type="html"><![CDATA[<h4 id="课程大纲"><a href="#课程大纲" class="headerlink" title="课程大纲"></a>课程大纲</h4><p>来自慕课教程：<a href="https://coding.imooc.com/class/167.html" target="_blank" rel="noopener">https://coding.imooc.com/class/167.html</a></p><p><img src="http://img.blog.csdn.net/20180222155834956?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20180222155843670?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><h5 id="第1章-课程介绍"><a href="#第1章-课程介绍" class="headerlink" title="第1章 课程介绍"></a>第1章 课程介绍</h5><p>1-1 导学</p><p>1-2 技术选型介绍</p><p>1-3 学习建议</p><h5 id="第2章-项目设计"><a href="#第2章-项目设计" class="headerlink" title="第2章 项目设计"></a>第2章 项目设计</h5><p>2-1 _需求分析</p><p>2-2 _数据库设计</p><h5 id="第3章-环境搭建"><a href="#第3章-环境搭建" class="headerlink" title="第3章 环境搭建"></a>第3章 环境搭建</h5><p>3-1 环境要求</p><p>3-2 后端框架搭建</p><p>3-3 集成单元测试及H2</p><p>3-4 前端集成</p><h5 id="第4章-架构设计"><a href="#第4章-架构设计" class="headerlink" title="第4章 架构设计"></a>第4章 架构设计</h5><p>4-1 架构设计与分层</p><p>4-2 API结构设计_RESTFul API</p><p>4-3 API结构设计_标准制定</p><p>4-4 API结构设计_异常拦截器</p><p>4-5 功能性页面开发</p><h5 id="第5章-后台管理模块实现"><a href="#第5章-后台管理模块实现" class="headerlink" title="第5章 后台管理模块实现"></a>第5章 后台管理模块实现</h5><p>5-1 业务与功能分析设计</p><p>5-2 后台登录功能实现</p><p>5-3 权限控制</p><p>5-4 验证失败逻辑处理</p><h5 id="第6章-房源信息管理模块实现"><a href="#第6章-房源信息管理模块实现" class="headerlink" title="第6章 房源信息管理模块实现"></a>第6章 房源信息管理模块实现</h5><p>6-1 业务与功能分析设计_</p><p>6-2 基于七牛云的图片上传</p><p>6-3 基于七牛云的图片上传_本地上传</p><p>6-4 基于七牛云的图片上传_上云1</p><p>6-5 基于七牛云的图片上传_上云2</p><p>6-6 新增房源信息功能实现_上</p><p>6-7 新增房源信息功能实现_中</p><p>6-8 新增房源信息功能实现_下</p><p>6-9 房源浏览功能实现_基本开发</p><p>6-10 房源浏览功能实现_分页实现</p><p>6-11 房源浏览功能实现_多维度排序</p><p>6-12 编辑功能实现_上</p><p>6-13 编辑功能实现_下</p><p>6-14 审核功能实现</p><h5 id="第7章-基础功能实现"><a href="#第7章-基础功能实现" class="headerlink" title="第7章 基础功能实现"></a>第7章 基础功能实现</h5><p>7-1 功能与分析设计</p><p>7-2 默认排序实现（上）</p><p>7-3 默认排序实现（下）</p><p>7-4 其他维度排序实现</p><p>7-5 房源信息详情页</p><h5 id="第8章-搜索引擎实现"><a href="#第8章-搜索引擎实现" class="headerlink" title="第8章 搜索引擎实现"></a>第8章 搜索引擎实现</h5><p>8-1 业务与功能分析</p><p>8-2 ES与MySQL技术选型对比</p><p>8-3 索引结构设计（上）</p><p>8-4 索引结构设计（下）</p><p>8-5 索引构建_核心逻辑（上）</p><p>8-6 索引构建_核心逻辑（下）</p><p>8-7 索引构建-消息中间件介绍</p><p>8-8 索引构建_异步实现</p><p>8-9 搜索引擎_上</p><p>8-10 搜索引擎_下</p><p>8-11 中文分词_问题描述</p><p>8-12 中文分词_巧解之道</p><p>8-13 Search-as-you-type</p><p>8-14 小区房源统计功能</p><p>8-15 搜索引擎优化</p><h5 id="第9章-基于百度地图的找房功能"><a href="#第9章-基于百度地图的找房功能" class="headerlink" title="第9章 基于百度地图的找房功能"></a>第9章 基于百度地图的找房功能</h5><p>9-1 _业务与功能分析</p><p>9-2 _基于ES的地图点聚合（上）</p><p>9-3 _基于ES的地图点聚合（下）</p><p>9-4 地图鼠标事件应用</p><p>9-5 基于地址获取经纬度的开发实现</p><p>9-6 基于ES的地图查询功能</p><p>9-7 基于ES的视野数据源绑定</p><p>9-8 基于百度LBS的云麻点_POI数据增删改（上）</p><p>9-9 基于百度LBS的云麻点_POI数据增删改（下）</p><p>9-10 基于百度LBS的云麻点_POI数据应用</p><h5 id="第10章-会员系统"><a href="#第10章-会员系统" class="headerlink" title="第10章 会员系统"></a>第10章 会员系统</h5><p>10-1 业务与功能分析_</p><p>10-2 免注册登录_核心逻辑</p><p>10-3 免注册登录_阿里云实现-</p><p>10-4 会员中心</p><p>10-5 用户预约功能（上）</p><p>10-6 用户预约功能（下）</p><p>10-7 经纪人完成预约功能</p><p>10-8 _api权限拦截器</p><p>10-9 _基于美洽的客服系统</p><h5 id="第11章-ElasticSearch优化"><a href="#第11章-ElasticSearch优化" class="headerlink" title="第11章 ElasticSearch优化"></a>第11章 ElasticSearch优化</h5><p>11-1 索引结构优化</p><p>11-2 配置优化</p><p>11-3 基于Nginx实现负载均衡</p><p>11-4 安全控制_基本认证</p><p>11-5 安全控制_选择性认证</p><p>11-6 基于SpringSchedule的监控任务</p><p>11-7 基于SpringMail的报警系统</p><h5 id="第12章-基于ELK的应用分析"><a href="#第12章-基于ELK的应用分析" class="headerlink" title="第12章 基于ELK的应用分析"></a>第12章 基于ELK的应用分析</h5><p>12-1 <em>业务与功能分析设计</em></p><p>12-2 Logstash应用_日志采集</p><p>12-3 Logstash应用_Nginx日志拆解入库</p><p>12-4 <em>数据可视化分析</em>全局流量趋势</p><p>12-5 <em>数据可视化分析</em>房源访问流量趋势图</p><h5 id="第13章-项目上线"><a href="#第13章-项目上线" class="headerlink" title="第13章 项目上线"></a>第13章 项目上线</h5><p>13-1 <em>单元测试覆盖率报告.mov</em>音频</p><p>13-2 _线上线下配置分离</p><h5 id="第14章-课程总结"><a href="#第14章-课程总结" class="headerlink" title="第14章 课程总结"></a>第14章 课程总结</h5><p>14-1 <em>课程总结</em></p><h4 id="教程截图"><a href="#教程截图" class="headerlink" title="教程截图"></a>教程截图</h4><p><img src="http://img.blog.csdn.net/20180222155851304?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20180222155858235?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20180222155905892?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><h4 id="更多教程"><a href="#更多教程" class="headerlink" title="更多教程"></a>更多教程</h4><p>教程不断整理更新中，以上截图仅供参考，如需了解更多视频教程的详细信息请到如下地址查看：<a href="http://hfbin.cn" target="_blank" rel="noopener">http://hfbin.cn</a><br>教程分类说明：<a href="http://hfbin.cn/categories/" target="_blank" rel="noopener">http://hfbin.cn/categories/</a></p><h4 id="获取方式"><a href="#获取方式" class="headerlink" title="获取方式"></a>获取方式</h4><p><a href="http://hfbin.cn/2018/02/21/buy-%E5%85%B3%E4%BA%8E%E6%95%99%E7%A8%8B%E3%80%81%E8%8E%B7%E5%8F%96%E6%96%B9%E5%BC%8F%E3%80%81%E6%B8%A9%E9%A6%A8%E6%8F%90%E7%A4%BA/" target="_blank" rel="noopener">关于教程、获取方式、温馨提示</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;课程大纲&quot;&gt;&lt;a href=&quot;#课程大纲&quot; class=&quot;headerlink&quot; title=&quot;课程大纲&quot;&gt;&lt;/a&gt;课程大纲&lt;/h4&gt;&lt;p&gt;来自慕课教程：&lt;a href=&quot;https://coding.imooc.com/class/167.html&quot; targe
      
    
    </summary>
    
      <category term="java系列视频教程" scheme="http://yoursite.com/categories/java%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="java系列视频教程" scheme="http://yoursite.com/tags/java%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Google面试官亲授 升级Java面试</title>
    <link href="http://yoursite.com/2018/02/22/buy-Google%E9%9D%A2%E8%AF%95%E5%AE%98%E4%BA%B2%E6%8E%88%20%E5%8D%87%E7%BA%A7Java%E9%9D%A2%E8%AF%95/"/>
    <id>http://yoursite.com/2018/02/22/buy-Google面试官亲授 升级Java面试/</id>
    <published>2018-02-22T08:46:11.000Z</published>
    <updated>2018-02-22T08:01:53.573Z</updated>
    
    <content type="html"><![CDATA[<h4 id="课程大纲"><a href="#课程大纲" class="headerlink" title="课程大纲"></a>课程大纲</h4><p>来自慕课教程：<a href="https://coding.imooc.com/class/132.html" target="_blank" rel="noopener">https://coding.imooc.com/class/132.html</a></p><p><img src="http://img.blog.csdn.net/20180222155157750?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20180222155207485?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><h5 id="第1章-课程引言"><a href="#第1章-课程引言" class="headerlink" title="第1章 课程引言"></a>第1章 课程引言</h5><p>1-1 _导学</p><p>1-2 校招录取率和在线笔试</p><p>1-3 从一道谷歌在线笔试开始</p><h5 id="第2章-操作系统"><a href="#第2章-操作系统" class="headerlink" title="第2章 操作系统"></a>第2章 操作系统</h5><p>2-1 操作系统_概述</p><p>2-2 进程和线程</p><p>2-3 存储和寻址</p><p>2-4 进程间通信</p><p>2-5 操作系统问题</p><p>2-6 操作系统_例题</p><h5 id="第3章-网-络"><a href="#第3章-网-络" class="headerlink" title="第3章 网 络"></a>第3章 网 络</h5><p>3-1 网络基础</p><p>3-2 滑动窗口问题</p><p>3-3 网络抓包演示</p><p>3-4 TCP问题</p><p>3-5 TCP链接建立与断开</p><p>3-6 网络例题</p><h5 id="第4章-数据库"><a href="#第4章-数据库" class="headerlink" title="第4章 数据库"></a>第4章 数据库</h5><p>4-1 数据库_概述</p><p>4-2 JOIN和GROUP BY</p><p>4-3 事务和乐观锁</p><p>4-4 数据库问题</p><p>4-5 索引的创建和验证</p><p>4-6 索引的实现</p><p>4-7 数据库连接池</p><p>4-8 数据库例题</p><h5 id="第5章-程序设计语言基础"><a href="#第5章-程序设计语言基础" class="headerlink" title="第5章 程序设计语言基础"></a>第5章 程序设计语言基础</h5><p>5-1 程序设计语言基础_归类</p><p>5-2 程序语言问题</p><p>5-3 数据类型、整数和补码</p><p>5-4 浮点数和定点数简述</p><p>5-5 Java数据类型、拆箱和装箱</p><p>5-6 数据类型问题</p><h5 id="第6章-编码技巧"><a href="#第6章-编码技巧" class="headerlink" title="第6章 编码技巧"></a>第6章 编码技巧</h5><p>6-1 编码技巧_概述</p><p>6-2 在白板上写程序</p><p>6-3 数学归纳法是编码的依据</p><p>6-4 编码技巧_递归书写方法</p><p>6-5 递归控制<em>例题链表创建</em></p><p>6-6 递归控制<em>例题链表反转</em></p><p>6-7 递归控制_例题列出所有组合</p><p>6-8 递归开销</p><p>6-9 编码技巧_循环书写方法</p><p>6-10 循环控制_例题链表反转非递归</p><p>6-11 循环控制_例题链表删除结点</p><p>6-12 边界控制_二分查找</p><p>6-13 二分查找_设计测试用例和隐藏10年的bug</p><p>6-14 数据结构回顾</p><p>6-15 Java集合类型常见问题</p><p>6-16 树的遍历</p><p>6-17 树的遍历_构造后序</p><p>6-18 中序遍历下一个结点_分析</p><p>6-19 中序遍历下一个结点_代码</p><p>6-20 树的遍历_例题</p><p>6-21 算法复杂度</p><p>6-22 编码技巧_总结</p><h5 id="第7章-面向对象"><a href="#第7章-面向对象" class="headerlink" title="第7章 面向对象"></a>第7章 面向对象</h5><p>7-1 面向对象_概述</p><p>7-2 面向对象_类与对象</p><p>7-3 对象的特殊函数（上）</p><p>7-4 对象的特殊函数（下）</p><p>7-5 接口与抽象类</p><p>7-6 实现Iterable接口</p><p>7-7 继承</p><p>7-8 封装</p><p>7-9 面向对象_例题</p><p>7-10 面向对象_不可变性</p><p>7-11 泛型（上）</p><p>7-12 泛型（下）</p><p>7-13 虚函数表</p><p>7-14 面向对象_小结</p><p>7-15 面向对象问题</p><h5 id="第8章-设计模式"><a href="#第8章-设计模式" class="headerlink" title="第8章 设计模式"></a>第8章 设计模式</h5><p>8-1 设计模式简介</p><p>8-2 State模式</p><p>8-3 _Decorator模式</p><p>8-4 创建对象</p><h5 id="第9章-高级知识点"><a href="#第9章-高级知识点" class="headerlink" title="第9章 高级知识点"></a>第9章 高级知识点</h5><p>9-1 高级知识点</p><p>9-2 外部排序分析</p><p>9-3 死锁分析</p><p>9-4 线程池介绍</p><p>9-5 线程池_Java Excutor Framework演示（上）</p><p>9-6 线程池_Java Excutor Framework演示（下）</p><p>9-7 服务器Socket编程</p><p>9-8 线程池实现服务器</p><p>9-9 NIO服务器</p><p>9-10 select模型的缺点</p><p>9-11 go语言实现异步服务器</p><p>9-12 资源管理</p><p>9-13 Java进阶知识点介绍</p><p>9-14 Java垃圾回收(上)</p><p>9-15 Java垃圾回收(下)</p><p>9-16 Java内存模型1</p><p>9-17 Java内存模型2</p><p>9-18 异常处理</p><p>9-19 架构演进</p><h5 id="第10章-谷歌在线笔试题解"><a href="#第10章-谷歌在线笔试题解" class="headerlink" title="第10章 谷歌在线笔试题解"></a>第10章 谷歌在线笔试题解</h5><p>10-1 解小数据集</p><p>10-2 估算算法时间</p><p>10-3 解大数据集（上）</p><p>10-4 解大数据集（下）</p><p>10-5 运气和异常</p><h5 id="第11章-面试的软技巧和总结"><a href="#第11章-面试的软技巧和总结" class="headerlink" title="第11章 面试的软技巧和总结"></a>第11章 面试的软技巧和总结</h5><p>11-1 面试过程和注意点</p><p>11-2 总结</p><h4 id="教程截图"><a href="#教程截图" class="headerlink" title="教程截图"></a>教程截图</h4><p><img src="http://img.blog.csdn.net/20180222155217596?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20180222155228877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20180222155236515?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzM1MjQxNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><h4 id="更多教程"><a href="#更多教程" class="headerlink" title="更多教程"></a>更多教程</h4><p>教程不断整理更新中，以上截图仅供参考，如需了解更多视频教程的详细信息请到如下地址查看：<a href="http://hfbin.cn" target="_blank" rel="noopener">http://hfbin.cn</a><br>教程分类说明：<a href="http://hfbin.cn/categories/" target="_blank" rel="noopener">http://hfbin.cn/categories/</a></p><h4 id="获取方式"><a href="#获取方式" class="headerlink" title="获取方式"></a>获取方式</h4><p><a href="http://hfbin.cn/2018/02/21/buy-%E5%85%B3%E4%BA%8E%E6%95%99%E7%A8%8B%E3%80%81%E8%8E%B7%E5%8F%96%E6%96%B9%E5%BC%8F%E3%80%81%E6%B8%A9%E9%A6%A8%E6%8F%90%E7%A4%BA/" target="_blank" rel="noopener">关于教程、获取方式、温馨提示</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;课程大纲&quot;&gt;&lt;a href=&quot;#课程大纲&quot; class=&quot;headerlink&quot; title=&quot;课程大纲&quot;&gt;&lt;/a&gt;课程大纲&lt;/h4&gt;&lt;p&gt;来自慕课教程：&lt;a href=&quot;https://coding.imooc.com/class/132.html&quot; targe
      
    
    </summary>
    
      <category term="java面试系列教程" scheme="http://yoursite.com/categories/java%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="java面试系列教程" scheme="http://yoursite.com/tags/java%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
</feed>
