<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="hdfs," />





  <link rel="alternate" href="/atom.xml" title="Fseast Blog" type="application/atom+xml" />






<meta name="description" content="一、HDFS概述HDFS(Hadoop distributed File System)，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。使用场景：适合一次写入，多次读写的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。 1.优点 高容错性（1）数据自动保存多个副本。它通过增加副本的形式，提">
<meta name="keywords" content="hdfs">
<meta property="og:type" content="article">
<meta property="og:title" content="（一）HDFS的认识及使用Java对其的简单操作">
<meta property="og:url" content="http://yoursite.com/2018/02/25/buy-（一）HDFS的认识及使用Java对其的简单操作/index.html">
<meta property="og:site_name" content="Fseast Blog">
<meta property="og:description" content="一、HDFS概述HDFS(Hadoop distributed File System)，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。使用场景：适合一次写入，多次读写的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。 1.优点 高容错性（1）数据自动保存多个副本。它通过增加副本的形式，提">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190720215137559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2019072022325670.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190728145944142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190728204453690.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190728225310129.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70">
<meta property="og:updated_time" content="2019-09-10T18:03:53.594Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="（一）HDFS的认识及使用Java对其的简单操作">
<meta name="twitter:description" content="一、HDFS概述HDFS(Hadoop distributed File System)，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。使用场景：适合一次写入，多次读写的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。 1.优点 高容错性（1）数据自动保存多个副本。它通过增加副本的形式，提">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20190720215137559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/02/25/buy-（一）HDFS的认识及使用Java对其的简单操作/"/>





  <title>（一）HDFS的认识及使用Java对其的简单操作 | Fseast Blog</title>
  








</head>
<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Fseast Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>
<!--  座右铭
<div class="site-brand-wrapper">
My friend promised me to go if I had the road
</div>
-->
<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            Über
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Kategorien
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/25/buy-（一）HDFS的认识及使用Java对其的简单操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="fseast">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://avatars0.githubusercontent.com/u/36739712?s=400&u=74c78513a2397b5152a72351de97c22dc3c060c5&v=4">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fseast Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">（一）HDFS的认识及使用Java对其的简单操作</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-25T21:23:17+08:00">
                2018-02-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="一、HDFS概述"><a href="#一、HDFS概述" class="headerlink" title="一、HDFS概述"></a>一、HDFS概述</h2><p>HDFS(Hadoop distributed File System)，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。<br>使用场景：适合一次写入，多次读写的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。</p>
<h3 id="1-优点"><a href="#1-优点" class="headerlink" title="1.优点"></a>1.优点</h3><ol>
<li>高容错性<br>（1）数据自动保存多个副本。它通过增加副本的形式，提高容错性。<br>（2）某一个副本丢失以后，它可以自动恢复。</li>
<li>适合处理大数据<br>（1）数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据；<br>（2）文件规模：能够处理百万规模以上的文件数量，数量相当之大。</li>
<li>可构建在廉价机器上，通过多副本机制，提高可靠性。</li>
</ol>
<h3 id="2-缺点"><a href="#2-缺点" class="headerlink" title="2.缺点"></a>2.缺点</h3><ol>
<li>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。</li>
<li>无法高效的对大量小文件进行存储。<br>（1）存储大量小文件的话，它会占用NameNode大量的内存来存储文件目录和块信息。这样是不可取的，因为NameNode的内存总是有限的；<br>（2）小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。</li>
<li>不支持并发写入、文件随机修改。<br>（1）一个文件只能有一个写，不允许多个线程同时写；<br>（2）仅支持数据append（追加），不支持文件的随时修改。</li>
</ol>
<h3 id="3-HDFS组成架构"><a href="#3-HDFS组成架构" class="headerlink" title="3.HDFS组成架构"></a>3.HDFS组成架构</h3><p>先通过一张图了解一下：<br><img src="https://img-blog.csdnimg.cn/20190720215137559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ol>
<li>NameNode（nn）：就是Master，它是一个主管、管理者。<br>（1）管理HDFS的名称空间；<br>（2）配置副本策略；<br>（3）管理数据库（Block）映射信息；<br>（4）处理客户端读写请求。</li>
<li>DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。<br>（1）存储实际的数据块；<br>（2）执行数据块的读/写操作。</li>
<li>Secondary NameNode：并非NameNode的热备份。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。<br>（1）辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode；<br>（2）在紧急情况下，可辅助恢复NameNode。</li>
</ol>
<h3 id="4-HDFS文件块大小"><a href="#4-HDFS文件块大小" class="headerlink" title="4.HDFS文件块大小"></a>4.HDFS文件块大小</h3><p>HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数（dfs.blocksize）来规定，默认大小在Hadoop2.x版本中是128M，老版本中是64M。<br><img src="https://img-blog.csdnimg.cn/2019072022325670.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="HDFS文件块大小"></p>
<p>【问题：】为什么块的大小不能设置太小，也不能设置太大？<br>（1）HDFS的块设置太小，会增加寻址时间，程序一直在找块的开始位置；<br>（2）如果块设置的太大，从磁盘传输数据的时间会明显大于定位这个块开始所需的时间。导致程序在处理这块数据时，会非常慢。</p>
<p>总结：HDFS块的大小设置主要取决于磁盘传输速率。</p>
<h2 id="二、HDFS的Shell操作"><a href="#二、HDFS的Shell操作" class="headerlink" title="二、HDFS的Shell操作"></a>二、HDFS的Shell操作</h2><ol>
<li>基本语法：（有两个）</li>
</ol>
<p><code>bin/hadoop fs  具体命令</code> 或者 <code>bin/hdfs dfs 具体命令</code><br>dfs 是 fs 的实现类。</p>
<ol>
<li>常用命令实操：<br>启动Hadoop集群：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ sbin/ start-dfs.sh</span><br><span class="line">[fseast@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>（1）-help：输出这个命令参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ hdfs dfs -help rm</span><br></pre></td></tr></table></figure></p>
<p>（2）-ls：显示目录信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ hdfs dfs -ls /</span><br></pre></td></tr></table></figure></p>
<p>（3）-mkdir：在HDFS上创建目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ hdfs dfs -mkdir -p /user/fseast/</span><br></pre></td></tr></table></figure>
<p>（4）-moveFromLocal：从本地剪切粘贴到HDFS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ vim testmoveFrom.txt </span><br><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ hdfs dfs -moveFromLocal ./testmoveFrom.txt /user/fseast/</span><br></pre></td></tr></table></figure>
<p>（5）-appendToFile：追加一个文件到已经存在的文件末尾</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ hdfs dfs -appendToFile NOTICE.txt /user/fseast/testmoveFrom.txt</span><br></pre></td></tr></table></figure>
<p>（6）-cat：显示文件内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ hdfs dfs -cat /user/fseast/testmoveFrom.txt</span><br></pre></td></tr></table></figure></p>
<p>（7）-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</p>
<p>（8）-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ hdfs dfs -copyFromLocal test001.txt /</span><br></pre></td></tr></table></figure></p>
<p>（9）-copyToLocal：从HDFS拷贝到本地</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ rm -rf test001.txt </span><br><span class="line">[fseast@hadoop102 hadoop-2.7.2]$ hdfs dfs -copyToLocal /test001.txt</span><br></pre></td></tr></table></figure>
<p>（10）-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</p>
<p>（11）-mv：在HDFS目录中移动文件</p>
<p>（12）-get：等同于copyToLocal，就是从HDFS下载文件到本地</p>
<p>（13）-getmerge：合并下载多个文件，比如HDFS的目录/user/fseast/test 下有多个文件：log.1 , log.2 , log.3 …</p>
<p>（14）-put：等同于copyFromLocal</p>
<p>（15）-tail：显示一个文件的末尾</p>
<p>（16）-rm：删除文件或文件夹</p>
<p>（17）-rmdir：删除空目录</p>
<p>（18）-du统计文件夹的大小信息</p>
<p>（19）-setrep：设置HDFS中文件的副本数量</p>
<h2 id="三、HDFS客户端操作"><a href="#三、HDFS客户端操作" class="headerlink" title="三、HDFS客户端操作"></a>三、HDFS客户端操作</h2><h3 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1.环境准备"></a>1.环境准备</h3><ol>
<li>创建Maven工程并导入相应得的依赖坐标     </li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>jdk.tools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jdk.tools<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>system<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">systemPath</span>&gt;</span>$&#123;JAVA_HOME&#125;/lib/tools.jar<span class="tag">&lt;/<span class="name">systemPath</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>需要在项目的src/main/resources目录下，新建一个文件，命名为log4j.properties，并在文件中填入（为了查看日志）：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, stdout</span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender</span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n</span><br><span class="line">log4j.appender.logfile=org.apache.log4j.FileAppender</span><br><span class="line">log4j.appender.logfile.File=target/spring.log</span><br><span class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</span><br></pre></td></tr></table></figure>
<ol>
<li>编写一个类，测试是否连接成功</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 连通客户端与HDFS的连接</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="meta">@Test</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testClientConnectHDFS</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">     Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">     FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), conf, <span class="string">"fseast"</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     <span class="comment">//在HDFS上创建一个目录</span></span><br><span class="line">     fs.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/HdfsDemo02/test01"</span>));</span><br><span class="line"></span><br><span class="line">     <span class="comment">//关闭资源</span></span><br><span class="line">     fs.close();</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-HDFS的API操作"><a href="#2-HDFS的API操作" class="headerlink" title="2.HDFS的API操作"></a>2.HDFS的API操作</h3><ol>
<li>HDFS文件上传（参数优先级）</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 测试1：上传文件到HDFS</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="meta">@Test</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCopyFromLocal</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">      <span class="comment">//1.获取FileSystem对象</span></span><br><span class="line">      Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">      <span class="comment">//可以设置多少个副本，优先级最高</span></span><br><span class="line">      configuration.set(<span class="string">"dfs.replication"</span>, <span class="string">"2"</span>);</span><br><span class="line">      FileSystem fileSystem = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//2.操作</span></span><br><span class="line">      fileSystem.copyFromLocalFile(<span class="keyword">new</span> Path(<span class="string">"e:/file/test/fsdong.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"/HdfsDemo02/test01"</span>));</span><br><span class="line"></span><br><span class="line">      <span class="comment">//3. 关闭资源</span></span><br><span class="line">      fileSystem.close();</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>可以将hdfs-site.xml拷贝到项目的根目录下。<br><strong>参数优先级：</strong><br>参数优先级排序：<br>（1）客户端代码中设置的值 &gt; （2）ClassPath 下的用户自定义配置文件 &gt;（3）然后是服务器的默认配置</p>
<ol>
<li>HDFS文件下载</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCopyToLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取文件系统</span></span><br><span class="line">		Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">		FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 执行下载操作</span></span><br><span class="line">		<span class="comment">// boolean delSrc 指是否将原文件删除</span></span><br><span class="line">		<span class="comment">// Path src 指要下载的文件路径</span></span><br><span class="line">		<span class="comment">// Path dst 指将文件下载到的路径</span></span><br><span class="line">		<span class="comment">// boolean useRawLocalFileSystem 是否开启文件校验</span></span><br><span class="line">		fs.copyToLocalFile(<span class="keyword">false</span>, <span class="keyword">new</span> Path(<span class="string">"/HdfsDemo02/test01/wc.input"</span>), <span class="keyword">new</span> Path(<span class="string">"e:/file/test/"</span>), <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 关闭资源</span></span><br><span class="line">		fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>HDFS文件夹删除</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testDelete</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 执行删除</span></span><br><span class="line">	fs.delete(<span class="keyword">new</span> Path(<span class="string">"/HdfsDemo01/"</span>), <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 关闭资源</span></span><br><span class="line">	fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>HDFS文件名更改</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testRename</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>); </span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 修改文件名称</span></span><br><span class="line">	fs.rename(<span class="keyword">new</span> Path(<span class="string">"/HdfsDemo02/test01/fsdong.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"/fseast.txt"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 关闭资源</span></span><br><span class="line">	fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>HDFS 文件详情查看<br>查看文件名称、权限、长度、块信息</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testListFiles</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>); </span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 获取文件详情</span></span><br><span class="line">	RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">while</span>(listFiles.hasNext())&#123;</span><br><span class="line">		LocatedFileStatus status = listFiles.next();</span><br><span class="line">			</span><br><span class="line">		<span class="comment">// 输出详情</span></span><br><span class="line">		<span class="comment">// 文件名称</span></span><br><span class="line">		System.out.println(status.getPath().getName());</span><br><span class="line">		<span class="comment">// 长度</span></span><br><span class="line">		System.out.println(status.getLen());</span><br><span class="line">		<span class="comment">// 权限</span></span><br><span class="line">		System.out.println(status.getPermission());</span><br><span class="line">		<span class="comment">// 分组</span></span><br><span class="line">		System.out.println(status.getGroup());</span><br><span class="line">			</span><br><span class="line">		<span class="comment">// 获取存储的块信息</span></span><br><span class="line">		BlockLocation[] blockLocations = status.getBlockLocations();</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">for</span> (BlockLocation blockLocation : blockLocations) &#123;</span><br><span class="line">				</span><br><span class="line">			<span class="comment">// 获取块存储的主机节点</span></span><br><span class="line">			String[] hosts = blockLocation.getHosts();</span><br><span class="line">				</span><br><span class="line">			<span class="keyword">for</span> (String host : hosts) &#123;</span><br><span class="line">				System.out.println(host);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">			</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 关闭资源</span></span><br><span class="line">fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>HDFS文件和文件夹判断</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testListStatus</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 1 获取文件配置信息</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 判断是文件还是文件夹</span></span><br><span class="line">	FileStatus[] listStatus = fs.listStatus(<span class="keyword">new</span> Path(<span class="string">"/"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">for</span> (FileStatus fileStatus : listStatus) &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 如果是文件</span></span><br><span class="line">		<span class="keyword">if</span> (fileStatus.isFile()) &#123;</span><br><span class="line">				System.out.println(<span class="string">"f:"</span>+fileStatus.getPath().getName());</span><br><span class="line">			&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">				System.out.println(<span class="string">"d:"</span>+fileStatus.getPath().getName());</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 关闭资源</span></span><br><span class="line">	fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>传入一个路径，递归将该路径下的所有的文件还有目录打印到控制台</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testListStatus</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">	fs  = FileSystem.get(<span class="keyword">new</span> URI(uri), conf,user);</span><br><span class="line">	printFileOrDir(<span class="string">"/"</span>, fs);</span><br><span class="line">	</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 传入一个路径 ，递归将该路径下的所有的文件还有目录打印到控制台</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">printFileOrDir</span><span class="params">(String path , FileSystem fs)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	</span><br><span class="line">	FileStatus[] listStatus = fs.listStatus(<span class="keyword">new</span> Path(path));</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">for</span> (FileStatus fileStatus : listStatus) &#123;</span><br><span class="line">		<span class="comment">//判断是文件还是目录</span></span><br><span class="line">		<span class="keyword">if</span>(fileStatus.isFile()) &#123;</span><br><span class="line">			System.out.println(<span class="string">"File:"</span> + path + <span class="string">"/"</span> + fileStatus.getPath().getName());</span><br><span class="line">		&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">// path:   hdfs://hadoop102:9000/0508</span></span><br><span class="line">			String currentPath = fileStatus.getPath().toString().substring(<span class="string">"hdfs://hadoop102:9000"</span>.length());</span><br><span class="line">			</span><br><span class="line">			<span class="comment">//打印当前的目录</span></span><br><span class="line">			System.out.println(<span class="string">"Dir:"</span> + currentPath);</span><br><span class="line">			</span><br><span class="line">			<span class="comment">//继续迭代当前目录下的子目录及文件</span></span><br><span class="line">			printFileOrDir(currentPath, fs);</span><br><span class="line">			fs.close();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-HDFS的I-O流操作"><a href="#3-HDFS的I-O流操作" class="headerlink" title="3.HDFS的I/O流操作"></a>3.HDFS的I/O流操作</h3><font color="#4169E1" size="4"> 1. HDFS文件上传 </font><br>需求：把本地E盘上 test02.txt 文件上传到HDFS根目录<br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putFileToHDFS</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2 创建输入流</span></span><br><span class="line">	FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"e:/test02.txt"</span>));</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 3 获取输出流</span></span><br><span class="line">	FSDataOutputStream fos = fs.create(<span class="keyword">new</span> Path(<span class="string">"/test02.txt"</span>));</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 4 流对拷</span></span><br><span class="line">	IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 5 关闭资源</span></span><br><span class="line">	IOUtils.closeStream(fos);</span><br><span class="line">	IOUtils.closeStream(fis);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><br><font color="#4169E1" size="4"> 2. HDFS文件下载 </font><br>需求：从HDFS上下载test02.txt文件到本地e盘上<br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 文件下载</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFileFromHDFS</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 获取输入流</span></span><br><span class="line">	FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/text02.txt"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 获取输出流</span></span><br><span class="line">	FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"e:/test02..txt"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 4 流的对拷</span></span><br><span class="line">	IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 5 关闭资源</span></span><br><span class="line">	IOUtils.closeStream(fos);</span><br><span class="line">	IOUtils.closeStream(fis);</span><br><span class="line">	fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><br><font color="#4169E1" size="4"> 3. 定位文件读取 </font><br>需求：分块读取HDFS上的大文件，比如根目录下的/hadoop-2.7.2.tar.gz（188M，大于128M所以上传到集群默认分成两块进行存储）<br><font color="#4169E1" size="3">（1）下载第一块： </font> 

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFileSeek1</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 获取输入流</span></span><br><span class="line">	FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/hadoop-2.7.2.tar.gz"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 创建输出流</span></span><br><span class="line">	FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"e:/hadoop-2.7.2.tar.gz.part1"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 4 流的拷贝</span></span><br><span class="line">	<span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span> ; i &lt; <span class="number">1024</span> * <span class="number">128</span>; i++)&#123;</span><br><span class="line">		fis.read(buf);</span><br><span class="line">		fos.write(buf);</span><br><span class="line">	&#125;</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 5关闭资源</span></span><br><span class="line">	IOUtils.closeStream(fis);</span><br><span class="line">	IOUtils.closeStream(fos);</span><br><span class="line">fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<font color="#4169E1" size="3">（2）下载第二块<br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFileSeek2</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"fseast"</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 打开输入流</span></span><br><span class="line">	FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/hadoop-2.7.2.tar.gz"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 定位输入数据位置</span></span><br><span class="line">	fis.seek(<span class="number">1024</span>*<span class="number">1024</span>*<span class="number">128</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 4 创建输出流</span></span><br><span class="line">	FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"e:/hadoop-2.7.2.tar.gz.part2"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 5 流的对拷</span></span><br><span class="line">	IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 6 关闭资源</span></span><br><span class="line">	IOUtils.closeStream(fis);</span><br><span class="line">	IOUtils.closeStream(fos);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><br><font color="#4169E1" size="3"><br>（3）将下载到的两块文件合并查看是否完整<br>在Windows命令窗口中进入到目录E:\，然后执行如下命令，对数据进行合并：<br><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">type hadoop-2.7.2.tar.gz.part2 &gt;&gt; hadoop-2.7.2.tar.gz.part1</span><br></pre></td></tr></table></figure><br><br>合并完成后，将hadoop-2.7.2.tar.gz.part1 重新命名为hadoop-2.7.2.tar.gz。解压发现该包是完整的。<br><br>## 四、HDFS的数据流<br>### 1.HDFS写数据流程<br>#### 2.1剖析文件写入<br><img src="https://img-blog.csdnimg.cn/20190728145944142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><font color="#4169E1" size="4">步骤分析： </font>

<p>（1）客户端通过 Distributed FileSystem 模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。<br>（2）NameNode返回是否可以上传。<br>（3）客户端请求第一个 Block 上传到那几个 DataNode 服务器上。<br>（4）NameNode 返回3个 DataNode节点（默认备份3份的情况下），分别为dn1，dn2，dn3,。<br>（5）客户端通过 FSDataOutputStream 模块请求dn1上传数据，dn1 收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。<br>（6）通道建立完成后，dn3应答dn2，dn2会答dn1，最后dn1应答客户端。<br>（7）客户端开始往dn1 上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。（DataNode收到Packet会先存到本地磁盘，再把缓存中的Packet传到下一个DataNode）。全部存完从dn3开始往回应答。<br>（8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block到服务器。重复执行3-7的步骤。<br>（9）传输完成以后，客户端会告诉NameNode数据传输完成。</p>
<h4 id="2-2网络拓扑-节点距离计算"><a href="#2-2网络拓扑-节点距离计算" class="headerlink" title="2.2网络拓扑 - 节点距离计算"></a>2.2网络拓扑 - 节点距离计算</h4><p>在HDFS写数据的过程中，NameNode会选择距离带上传数据最近距离的DataNode接受数据。</p>
<p><font color="#4169E1" size="4">最近距离如何计算</font><br>节点距离：两个节点到达最近的共同祖先的距离总和。看图更清晰：<br>假设有数据中心d1机架r1中的节点n1.该节点可以表示为/d1/r1/n1。利用这种标记，这里给出四种距离描述。<br><img src="https://img-blog.csdnimg.cn/20190728204453690.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="2-3Hadoop2-7-2-副本节点选择"><a href="#2-3Hadoop2-7-2-副本节点选择" class="headerlink" title="2.3Hadoop2.7.2 副本节点选择"></a>2.3Hadoop2.7.2 副本节点选择</h4><p>默认三个副本情况下的副本节点选择：<br>第一个副本在Client所处的节点上。如果客户端在集群外，随机选一个。<br>第二个副本和第一个副本位于相同机架，随机节点。<br>第三个副本位于不同机架，随机节点。</p>
<h3 id="2-HDFS读数据流程"><a href="#2-HDFS读数据流程" class="headerlink" title="2.HDFS读数据流程"></a>2.HDFS读数据流程</h3><p><img src="https://img-blog.csdnimg.cn/20190728225310129.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZzZWFzdA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><font color="#4169E1" size="4">步骤分析:</font><br>（1）客户端通过 Distributed FileSystem 向 NameNode 请求下载文件，NameNode 通过查找元数据，找到文件块所在的DataNode地址。<br>（2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。<br>（3）DataNode开始传输数据给客户端（从磁盘读取数据输入流，以Packet）为单位来做校验。<br>（4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。<br>（5）然后接着读取 第二个Block。</p>
</font></font>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hdfs/" rel="tag"><i class="fa fa-tag"></i> hdfs</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/02/23/buy-阿里云服务器上的Hadoop伪分布式和完全分布式的搭建/" rel="next" title="阿里云服务器上的Hadoop伪分布式和完全分布式的搭建">
                <i class="fa fa-chevron-left"></i> 阿里云服务器上的Hadoop伪分布式和完全分布式的搭建
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/07/buy-（二）HDFS——节点分析及新特性/" rel="prev" title="（二）HDFS——节点分析及新特性">
                （二）HDFS——节点分析及新特性 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_fav">收藏夹</a>
<a class="jiathis_button_copy">复制网址</a>
<a class="jiathis_button_email">邮件</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_qzone">QQ空间</a>
<a class="jiathis_button_tqq">腾讯微博</a>
<a class="jiathis_button_douban">豆瓣</a>
<a class="jiathis_button_share">一键分享</a>

<a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
var jiathis_config={
  data_track_clickback:true,
  summary:"",
  shortUrl:false,
  hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script>
<!-- JiaThis Button END -->
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://avatars0.githubusercontent.com/u/36739712?s=400&u=74c78513a2397b5152a72351de97c22dc3c060c5&v=4"
                alt="fseast" />
            
              <p class="site-author-name" itemprop="name">fseast</p>
              <p class="site-description motion-element" itemprop="description">My friend promised me to go if I had the road</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">Kategorien</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">Tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/fseast" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://blog.csdn.net/a1961554715" target="_blank" title="csdn">
                      
                        <i class="fa fa-fw fa-globe"></i>csdn</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/5137459330/profile?topnav=1&wvr=6&is_all=1" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-globe"></i>Weibo</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、HDFS概述"><span class="nav-number">1.</span> <span class="nav-text">一、HDFS概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-优点"><span class="nav-number">1.1.</span> <span class="nav-text">1.优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-缺点"><span class="nav-number">1.2.</span> <span class="nav-text">2.缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-HDFS组成架构"><span class="nav-number">1.3.</span> <span class="nav-text">3.HDFS组成架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-HDFS文件块大小"><span class="nav-number">1.4.</span> <span class="nav-text">4.HDFS文件块大小</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、HDFS的Shell操作"><span class="nav-number">2.</span> <span class="nav-text">二、HDFS的Shell操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、HDFS客户端操作"><span class="nav-number">3.</span> <span class="nav-text">三、HDFS客户端操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-环境准备"><span class="nav-number">3.1.</span> <span class="nav-text">1.环境准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-HDFS的API操作"><span class="nav-number">3.2.</span> <span class="nav-text">2.HDFS的API操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-HDFS的I-O流操作"><span class="nav-number">3.3.</span> <span class="nav-text">3.HDFS的I/O流操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2网络拓扑-节点距离计算"><span class="nav-number">3.3.1.</span> <span class="nav-text">2.2网络拓扑 - 节点距离计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3Hadoop2-7-2-副本节点选择"><span class="nav-number">3.3.2.</span> <span class="nav-text">2.3Hadoop2.7.2 副本节点选择</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-HDFS读数据流程"><span class="nav-number">3.4.</span> <span class="nav-text">2.HDFS读数据流程</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heartbeat"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fseast</span>

  
</div>


 <!-- 
 <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>
-->






<div class="busuanzi-count">
  

    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>


    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>

</div>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<div class="copyright display_zhanzhang"  style="text-align: center !important;">
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1272942984'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s13.cnzz.com/z_stat.php%3Fid%3D1272942984%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script></div>


        
		

        
      </div>
	  
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
</html>
